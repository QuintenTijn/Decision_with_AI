{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8bc82e2",
   "metadata": {},
   "source": [
    "# Imports & loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71aeb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from support import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2cd22c",
   "metadata": {},
   "source": [
    "#### Print Python and PyTorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python version:\", os.sys.version)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e549c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset()\n",
    "train_dataset = data[0]\n",
    "test_dataset = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fe5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_dataset[0]\n",
    "\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d010dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor, label = train_dataset[0]\n",
    "transform_to_pil = T.ToPILImage()\n",
    "img_pil = transform_to_pil(img_tensor)\n",
    "\n",
    "plt.imshow(img_pil)\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be77b74f",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e629039",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7eeaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_channels, input_height, input_width, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 16 x H/2 x W/2\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)   # Output: 32 x H/4 x W/4\n",
    "        )\n",
    "        \n",
    "        # Calculate the flattened size dynamically to connect conv layers to fc layers\n",
    "        with torch.no_grad(): # We don't need gradients for this calculation\n",
    "            dummy_input = torch.zeros(1, input_channels, input_height, input_width)\n",
    "            flattened_size = self.conv_layers(dummy_input).flatten(1).shape[1]\n",
    "            \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            nn.ReLU(),\n",
    "            # Output 1 logit for binary classification (labels 0 or 1)\n",
    "            # This will be used with BCEWithLogitsLoss\n",
    "            nn.Linear(128, 1 if num_classes == 2 else num_classes) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.flatten(1) # Flatten all dimensions except batch\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img, _ = train_dataset[0]\n",
    "C, H, W = sample_img.shape\n",
    "print(f\"Detected image shape: Channels={C}, Height={H}, Width={W}\")\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 64 # Adjust this based on memory\n",
    "num_epochs = 10  # Adjust as needed for convergence\n",
    "num_classes = 2  # Binary classification (labels 0 and 1)\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# DataLoaders\n",
    "pin_memory_flag = True if device.type == 'cuda' else False\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=pin_memory_flag)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=pin_memory_flag)\n",
    "\n",
    "model = SimpleCNN(input_channels=C, input_height=H, input_width=W, num_classes=num_classes).to(device)\n",
    "\n",
    "# Binary Cross Entropy with Logits Loss, suitable for binary classification with one output neuron\n",
    "criterion = nn.BCEWithLogitsLoss() # Different choiches possible\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        # Reshape labels to [batch_size, 1] and convert to float for BCEWithLogitsLoss\n",
    "        labels = labels.to(device).float().unsqueeze(1) \n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % max(1, len(train_loader) // 10) == 0: # Print progress, e.g. 10 times per epoch\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_epoch_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed. Average Training Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "    # Evaluation on the test set\n",
    "    model.eval()  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): \n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).float().unsqueeze(1) #\n",
    "            \n",
    "            outputs = model(images)\n",
    "            # Apply sigmoid to logits, then threshold at 0.5 for predictions #? Why this threshold?\n",
    "                                                                                # This is because BCEWithLogitsLoss combines a sigmoid layer and the BCELoss in one single class.\n",
    "                                                                                # The output of the model is a logit, which we convert to a probability using sigmoid.\n",
    "                                                                                # We then threshold at 0.5 to get binary predictions.\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float() \n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy on test set after epoch {epoch+1}: {accuracy:.2f}%\")\n",
    "\n",
    "# Save the model\n",
    "model_path = \"simple_cnn_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Finished Training\")\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc6deb",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c0f870",
   "metadata": {},
   "source": [
    "## Increased complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d470596",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, input_channels, input_height, input_width, num_classes,\n",
    "                 conv1_out_channels=16, conv2_out_channels=32, fc_neurons=128):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, conv1_out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: conv1_out_channels x H/2 x W/2\n",
    "            nn.Conv2d(conv1_out_channels, conv2_out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)   # Output: conv2_out_channels x H/4 x W/4\n",
    "        )\n",
    "        \n",
    "        # Calculate the flattened size dynamically\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, input_channels, input_height, input_width)\n",
    "            flattened_size = self.conv_layers(dummy_input).flatten(1).shape[1]\n",
    "            \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(flattened_size, fc_neurons),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(fc_neurons, 1 if num_classes == 2 else num_classes) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.flatten(1) # Flatten all dimensions except batch\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e13a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img, _ = train_dataset[0]\n",
    "C, H, W = sample_img.shape\n",
    "print(f\"Detected image shape: Channels={C}, Height={H}, Width={W}\")\n",
    "\n",
    "# Hyperparameters (Base Model)\n",
    "learning_rate = 0.001\n",
    "batch_size = 64 \n",
    "num_epochs = 10 \n",
    "num_classes = 2 \n",
    "\n",
    "# Default architectural parameters for the base model\n",
    "conv1_out_channels_base = 16\n",
    "conv2_out_channels_base = 32\n",
    "fc_neurons_base = 128\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# DataLoaders\n",
    "pin_memory_flag = True if device.type == 'cuda' else False\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=pin_memory_flag)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=pin_memory_flag)\n",
    "\n",
    "# Use the (potentially modified) SimpleCNN class\n",
    "model = SimpleCNN(input_channels=C, input_height=H, input_width=W, num_classes=num_classes,\n",
    "                    conv1_out_channels=conv1_out_channels_base, \n",
    "                    conv2_out_channels=conv2_out_channels_base, \n",
    "                    fc_neurons=fc_neurons_base).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Lists to store metrics for plotting\n",
    "epoch_train_losses = []\n",
    "epoch_test_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\")\n",
    "    for images, labels in train_pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float().unsqueeze(1) \n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0) # loss.item() is avg loss for batch\n",
    "        train_pbar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    avg_epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_train_losses.append(avg_epoch_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed. Average Training Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "    # Evaluation on the test set\n",
    "    model.eval()  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_pbar = tqdm(test_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\")\n",
    "    with torch.no_grad(): \n",
    "        for images, labels in test_pbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).float().unsqueeze(1)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float() \n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    epoch_test_accuracies.append(accuracy)\n",
    "    print(f\"Accuracy on test set after epoch {epoch+1}: {accuracy:.2f}%\")\n",
    "\n",
    "# Save the model\n",
    "model_path = \"complex_cnn_model.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Finished Training Base Model\")\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293f4b5",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ffc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting learning curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), epoch_train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), epoch_test_accuracies, label='Test Accuracy', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Test Accuracy Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca0754c",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e629c83",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device for hyperparameter tuning: {device}\")\n",
    "\n",
    "# Get image dimensions (C, H, W should be available from the previous cell or re-derived)\n",
    "if 'C' not in locals() or 'H' not in locals() or 'W' not in locals():\n",
    "    sample_img, _ = train_dataset[0]\n",
    "    C, H, W = sample_img.shape\n",
    "    print(f\"Re-detected image shape: Channels={C}, Height={H}, Width={W}\")\n",
    "\n",
    "# Hyperparameter search space\n",
    "param_space = {\n",
    "    'learning_rate': [0.0001, 0.0005, 0.001, 0.005, 0.01],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'conv1_out_channels': [8, 16, 32],\n",
    "    'conv2_out_channels': [16, 32, 64],\n",
    "    'fc_neurons': [64, 128, 256],\n",
    "    'optimizer_type': ['adam', 'sgd'] # Example of choosing optimizer\n",
    "}\n",
    "\n",
    "num_classes_hp = 2\n",
    "num_epochs_search = 5 # Fewer epochs for faster search, adjust as needed\n",
    "num_trials = 10 # Number of random hyperparameter sets to try\n",
    "\n",
    "best_hyperparams = None\n",
    "best_val_accuracy = -1.0\n",
    "best_model_state = None\n",
    "\n",
    "# Store history for the best model's learning curves\n",
    "best_model_train_losses = []\n",
    "best_model_val_accuracies = []\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    # Randomly sample hyperparameters\n",
    "    current_params = {k: random.choice(v) for k, v in param_space.items()}\n",
    "    print(f\"\\nTrial {trial+1}/{num_trials}: Testing params: {current_params}\")\n",
    "\n",
    "    # DataLoaders with current batch size\n",
    "    pin_memory_flag_hp = True if device.type == 'cuda' else False\n",
    "    try:\n",
    "        current_train_loader = DataLoader(train_dataset, batch_size=current_params['batch_size'], shuffle=True, num_workers=2, pin_memory=pin_memory_flag_hp)\n",
    "        current_val_loader = DataLoader(test_dataset, batch_size=current_params['batch_size'], shuffle=False, num_workers=2, pin_memory=pin_memory_flag_hp)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataLoader, possibly due to batch size: {e}. Skipping trial.\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Model\n",
    "    model_hp = SimpleCNN(input_channels=C, input_height=H, input_width=W, num_classes=num_classes_hp,\n",
    "                            conv1_out_channels=current_params['conv1_out_channels'],\n",
    "                            conv2_out_channels=current_params['conv2_out_channels'],\n",
    "                            fc_neurons=current_params['fc_neurons']).to(device)\n",
    "\n",
    "    criterion_hp = nn.BCEWithLogitsLoss()\n",
    "    if current_params['optimizer_type'] == 'adam':\n",
    "        optimizer_hp = optim.Adam(model_hp.parameters(), lr=current_params['learning_rate'])\n",
    "    elif current_params['optimizer_type'] == 'sgd':\n",
    "        optimizer_hp = optim.SGD(model_hp.parameters(), lr=current_params['learning_rate'], momentum=0.9)\n",
    "    else: # Default to Adam\n",
    "        optimizer_hp = optim.Adam(model_hp.parameters(), lr=current_params['learning_rate'])\n",
    "\n",
    "\n",
    "    trial_train_losses = []\n",
    "    trial_val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs_search):\n",
    "        model_hp.train()\n",
    "        epoch_running_loss = 0.0\n",
    "        train_pbar_hp = tqdm(current_train_loader, desc=f\"Trial {trial+1} Epoch {epoch+1} [Train]\", leave=False)\n",
    "        for images, labels in train_pbar_hp:\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "            optimizer_hp.zero_grad()\n",
    "            outputs = model_hp(images)\n",
    "            loss = criterion_hp(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_hp.step()\n",
    "            epoch_running_loss += loss.item() * images.size(0)\n",
    "            train_pbar_hp.set_postfix(loss=loss.item())\n",
    "        \n",
    "        avg_epoch_train_loss = epoch_running_loss / len(current_train_loader.dataset)\n",
    "        trial_train_losses.append(avg_epoch_train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model_hp.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_pbar_hp = tqdm(current_val_loader, desc=f\"Trial {trial+1} Epoch {epoch+1} [Val]\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_pbar_hp:\n",
    "                images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "                outputs = model_hp(images)\n",
    "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        current_epoch_val_accuracy = 100 * val_correct / val_total\n",
    "        trial_val_accuracies.append(current_epoch_val_accuracy)\n",
    "        \n",
    "        print(f\"Trial {trial+1} Epoch {epoch+1}: Train Loss: {avg_epoch_train_loss:.4f}, Val Accuracy: {current_epoch_val_accuracy:.2f}%\")\n",
    "\n",
    "    # Check if this trial is the best so far (based on final epoch's validation accuracy)\n",
    "    if trial_val_accuracies and current_epoch_val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = current_epoch_val_accuracy\n",
    "        best_hyperparams = current_params\n",
    "        best_model_state = model_hp.state_dict() # Save the model state\n",
    "        best_model_train_losses = trial_train_losses # Save learning curves for this best model\n",
    "        best_model_val_accuracies = trial_val_accuracies\n",
    "        print(f\"New best model found! Val Accuracy: {best_val_accuracy:.2f}%, Params: {best_hyperparams}\")\n",
    "\n",
    "print(\"\\nFinished Hyperparameter Search.\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622afaba",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f6e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Validation Accuracy: {best_val_accuracy:.2f}%\")\n",
    "print(f\"Best Hyperparameters: {best_hyperparams}\")\n",
    "\n",
    "# Plotting learning curves for the best model from hyperparameter search\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs_search + 1), best_model_train_losses, label='Best Model Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Best Model - Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs_search + 1), best_model_val_accuracies, label='Best Model Validation Accuracy', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Best Model - Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# You can now load the best model state for further use if needed:\n",
    "# model_best = SimpleCNN(input_channels=C, input_height=H, input_width=W, num_classes=num_classes_hp, **best_hyperparams_arch).to(device)\n",
    "# model_best.load_state_dict(best_model_state)\n",
    "# where best_hyperparams_arch = {k: v for k,v in best_hyperparams.items() if k in ['conv1_out_channels', 'conv2_out_channels', 'fc_neurons']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038ab6b",
   "metadata": {},
   "source": [
    "### Method 2 - Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e515a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device for Optuna hyperparameter tuning: {device}\")\n",
    "\n",
    "# Get image dimensions\n",
    "\n",
    "sample_img, _ = train_dataset[0]\n",
    "C, H, W = sample_img.shape\n",
    "print(f\"Image shape: Channels={C}, Height={H}, Width={W}\")\n",
    "\n",
    "num_classes_hp = 2\n",
    "num_epochs_search = 5 # Fewer epochs for faster search, adjust as needed for Optuna trials\n",
    "# num_trials_optuna = 20 # Number of Optuna trials to run\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameter suggestions\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    conv1_out = trial.suggest_categorical(\"conv1_out_channels\", [8, 16, 32, 64])\n",
    "    conv2_out = trial.suggest_categorical(\"conv2_out_channels\", [16, 32, 64, 128])\n",
    "    fc_neurons_val = trial.suggest_categorical(\"fc_neurons\", [64, 128, 256])\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer_type\", [\"adam\", \"sgd\"])\n",
    "\n",
    "    # DataLoaders\n",
    "    pin_memory_flag_opt = True if device.type == 'cuda' else False\n",
    "    try:\n",
    "        current_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=pin_memory_flag_opt)\n",
    "        current_val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=pin_memory_flag_opt)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DataLoader for trial {trial.number}: {e}. Pruning trial.\")\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "\n",
    "    # Model (Ensure SimpleCNN class is defined and accessible)\n",
    "    model_opt = SimpleCNN(input_channels=C, input_height=H, input_width=W, num_classes=num_classes_hp,\n",
    "                          conv1_out_channels=conv1_out,\n",
    "                          conv2_out_channels=conv2_out,\n",
    "                          fc_neurons=fc_neurons_val).to(device)\n",
    "\n",
    "    criterion_opt = nn.BCEWithLogitsLoss()\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer_opt = optim.Adam(model_opt.parameters(), lr=lr)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer_opt = optim.SGD(model_opt.parameters(), lr=lr, momentum=0.9)\n",
    "    else: # Should not happen with categorical suggestion\n",
    "        optimizer_opt = optim.Adam(model_opt.parameters(), lr=lr)\n",
    "\n",
    "    trial_train_losses = []\n",
    "    trial_val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs_search):\n",
    "        model_opt.train()\n",
    "        epoch_running_loss = 0.0\n",
    "        for images, labels in current_train_loader: # train_pbar_opt:\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "            \n",
    "            optimizer_opt.zero_grad()\n",
    "            outputs = model_opt(images)\n",
    "            loss = criterion_opt(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_opt.step()\n",
    "            epoch_running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        avg_epoch_train_loss = epoch_running_loss / len(current_train_loader.dataset)\n",
    "        trial_train_losses.append(avg_epoch_train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model_opt.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in current_val_loader: # val_pbar_opt:\n",
    "                images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "                outputs = model_opt(images)\n",
    "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        current_epoch_val_accuracy = 100 * val_correct / val_total if val_total > 0 else 0\n",
    "        trial_val_accuracies.append(current_epoch_val_accuracy)\n",
    "        \n",
    "        # Optuna pruning (optional, but good for long searches)\n",
    "        trial.report(current_epoch_val_accuracy, epoch)\n",
    "        if trial.should_prune():\n",
    "            # Store partial curves if pruned\n",
    "            trial.set_user_attr(\"train_losses\", trial_train_losses)\n",
    "            trial.set_user_attr(\"val_accuracies\", trial_val_accuracies)\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # Store full learning curves in user attributes for the trial\n",
    "    trial.set_user_attr(\"train_losses\", trial_train_losses)\n",
    "    trial.set_user_attr(\"val_accuracies\", trial_val_accuracies)\n",
    "            \n",
    "    return trial_val_accuracies[-1] # Return final validation accuracy\n",
    "\n",
    "# Create a study object and optimize\n",
    "# You can add a pruner, e.g., optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
    "num_trials_optuna = 20 # Define number of trials\n",
    "study.optimize(objective, n_trials=num_trials_optuna)\n",
    "\n",
    "print(\"\\nFinished Optuna Hyperparameter Search.\")\n",
    "best_trial_optuna = study.best_trial\n",
    "best_hyperparams_optuna = best_trial_optuna.params\n",
    "best_val_accuracy_optuna = best_trial_optuna.value\n",
    "\n",
    "print(f\"Best Validation Accuracy (Optuna): {best_val_accuracy_optuna:.2f}%\")\n",
    "print(f\"Best Hyperparameters (Optuna): {best_hyperparams_optuna}\")\n",
    "\n",
    "# Retrieve learning curves for the best trial\n",
    "best_model_train_losses_optuna = best_trial_optuna.user_attrs.get(\"train_losses\", [])\n",
    "best_model_val_accuracies_optuna = best_trial_optuna.user_attrs.get(\"val_accuracies\", [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1912c0ea",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6caca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Validation Accuracy (from Optuna study): {best_val_accuracy_optuna:.2f}%\")\n",
    "print(f\"Best Hyperparameters (from Optuna study): {best_hyperparams_optuna}\")\n",
    "\n",
    "# Plotting learning curves for the best model from Optuna hyperparameter search\n",
    "if best_model_train_losses_optuna and best_model_val_accuracies_optuna:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(best_model_train_losses_optuna) + 1), best_model_train_losses_optuna, label='Best Model Training Loss (Optuna)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Best Model (Optuna) - Training Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, len(best_model_val_accuracies_optuna) + 1), best_model_val_accuracies_optuna, label='Best Model Validation Accuracy (Optuna)', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Best Model (Optuna) - Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Learning curve data for the best Optuna trial is not available.\")\n",
    "    \n",
    "# You can now load the best model state for further use if needed.\n",
    "# First, you'd typically retrain a model with best_hyperparams_optuna for a full number of epochs\n",
    "# and save its state_dict. The state_dict is not directly saved by the Optuna objective function above.\n",
    "# Example:\n",
    "# model_best_optuna = SimpleCNN(input_channels=C, input_height=H, input_width=W, num_classes=num_classes_hp,\n",
    "#                               conv1_out_channels=best_hyperparams_optuna['conv1_out_channels'],\n",
    "#                               conv2_out_channels=best_hyperparams_optuna['conv2_out_channels'],\n",
    "#                               fc_neurons=best_hyperparams_optuna['fc_neurons']).to(device)\n",
    "# # Then, you would train this model_best_optuna using the best learning rate, optimizer, and batch size.\n",
    "# # For now, we are just plotting the curves from the optimization search itself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
